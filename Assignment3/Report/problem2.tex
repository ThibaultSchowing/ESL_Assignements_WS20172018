\section*{Problem 2}

\subsection*{a}
In which setting is logistic regression applicable? Why is linear regression not applicable in such a setting?\\

The logistic regression is applicable when the output space is restricted to being categorical (e.g. Y = 0 or 1). Linear regression is not applicable because the values are in the real domain and though can give values out of the desired range (e.g. negative values, when the output is between 0 and 1). 

\subsection*{b}
The odds formula is as below: 
\[ \frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1 X} \]

In a general meaning, odds and probabilities have the same signification but mathematically they are not the same. While a probability is expressed with a value between 0 and 1, the odds can have value from 0 to infinity. \\

In we take a classical example, we have a bag with 20 red balls, 40 blue and 40 yellow, so a total of 100 balls. The probability to get a red ball is $\frac{20}{100}$ but the odd is not the same. The denominator in the probability contains all the possibilities. In the odds, we remove the count of red balls so we have an odd to get a red ball of 20:80 which equals to $\frac{20}{80} = \frac{1}{4}$. So we have an odd of $\frac{1}{4}$ to pick up a red ball.  

\subsection*{c}

Prove that the equation $ p(X) = \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}} $ is equivalent to $\frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1 X}  $.\\

So we have $\frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1 X} $.

We simplify as follows:
\[ 1 - p(X) = 1 - \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}} = \frac{1 + e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}} - \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}}\]

So: 
\[ 1 - p(X) = \frac{1}{1 + e^{\beta_0 + \beta_1 X}} \]

We then replace in $\frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1 X}  $ and the two terms cancel:

\[ \frac{p(X)}{1 - p(X)} = \frac{e^{\beta_0 + \beta_1 X} (1 + e^{\beta_0 + \beta_1 X} )}{1 + e^{\beta_0 + \beta_1 X}} = e^{\beta_0 + \beta_1 X}  \]


